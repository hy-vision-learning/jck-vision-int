import torch
import torch.nn as nn


class_to_superclass = {
    4: 0, 30: 0, 55: 0, 72: 0, 95: 0,
    1: 1, 32: 1, 67: 1, 73: 1, 91: 1, 
    54: 2, 62: 2, 70: 2, 82: 2, 92: 2, 
    9: 3, 10: 3, 16: 3, 28: 3, 61: 3, 
    0: 4, 51: 4, 53: 4, 57: 4, 83: 4,
    22: 5, 39: 5, 40: 5, 86: 5, 87: 5,
    5: 6, 20: 6, 25: 6, 84: 6, 94: 6,
    6: 7, 7: 7, 14: 7, 18: 7, 24: 7,
    3: 8, 42: 8, 43: 8, 88: 8, 97: 8,
    12: 9, 17: 9, 37: 9, 68: 9, 76: 9,
    23: 10, 33: 10, 49: 10, 60: 10, 71: 10,
    15: 11, 19: 11, 21: 11, 31: 11, 38: 11,
    34: 12, 63: 12, 64: 12, 66: 12, 75: 12,
    26: 13, 45: 13, 77: 13, 79: 13, 99: 13,
    2: 14, 11: 14, 35: 14, 46: 14, 98: 14,
    27: 15, 29: 15, 44: 15, 78: 15, 93: 15,
    36: 16, 50: 16, 65: 16, 74: 16, 80: 16,
    47: 17, 52: 17, 56: 17, 59: 17, 96: 17,
    8: 18, 13: 18, 48: 18, 58: 18, 90: 18,
    41: 19, 69: 19, 81: 19, 85: 19, 89: 19
}
                

def get_default_device():
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')
